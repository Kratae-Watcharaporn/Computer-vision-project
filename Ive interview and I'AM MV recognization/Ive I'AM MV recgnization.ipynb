{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import face_recognition\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        image_path = os.path.join(folder, filename)\n",
    "        image = face_recognition.load_image_file(image_path)\n",
    "        images.append(image)\n",
    "    return images\n",
    "\n",
    "def encode_faces(images):\n",
    "    face_encodings = []\n",
    "    for image in images:\n",
    "        face_encoding = face_recognition.face_encodings(image)\n",
    "        if face_encoding:\n",
    "            face_encodings.append(face_encoding[0])\n",
    "    return face_encodings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_directory1 = \"C:/Mullika/MasterDegree/ComVision/DL-FOR-COMPUTER-VISION-main/DL-FOR-COMPUTER-VISION-main/week2/code/Working with Video/dataset/wonyoung/\"\n",
    "dataset_directory2 = \"C:/Mullika/MasterDegree/ComVision/DL-FOR-COMPUTER-VISION-main/DL-FOR-COMPUTER-VISION-main/week2/code/Working with Video/dataset/gaeul/\"\n",
    "dataset_directory3 = \"C:/Mullika/MasterDegree/ComVision/DL-FOR-COMPUTER-VISION-main/DL-FOR-COMPUTER-VISION-main/week2/code/Working with Video/dataset/rei/\"\n",
    "dataset_directory4 = \"C:/Mullika/MasterDegree/ComVision/DL-FOR-COMPUTER-VISION-main/DL-FOR-COMPUTER-VISION-main/week2/code/Working with Video/dataset/yujin/\"\n",
    "dataset_directory5 = \"C:/Mullika/MasterDegree/ComVision/DL-FOR-COMPUTER-VISION-main/DL-FOR-COMPUTER-VISION-main/week2/code/Working with Video/dataset/jiwon/\"\n",
    "dataset_directory6 = \"C:/Mullika/MasterDegree/ComVision/DL-FOR-COMPUTER-VISION-main/DL-FOR-COMPUTER-VISION-main/week2/code/Working with Video/dataset/leeseo/\"\n",
    "\n",
    "# Replace these paths with your actual dataset paths\n",
    "person1_images = dataset_directory1\n",
    "person2_images = dataset_directory2\n",
    "person3_images = dataset_directory3\n",
    "person4_images = dataset_directory4\n",
    "person5_images = dataset_directory5\n",
    "person6_images = dataset_directory6\n",
    "\n",
    "# Load images\n",
    "person1_images = load_images(person1_images)\n",
    "person2_images = load_images(person2_images)\n",
    "person3_images = load_images(person3_images)\n",
    "person4_images = load_images(person4_images)\n",
    "person5_images = load_images(person5_images)\n",
    "person6_images = load_images(person6_images)\n",
    "\n",
    "# Encode faces\n",
    "person1_face_encodings = encode_faces(person1_images)\n",
    "person2_face_encodings = encode_faces(person2_images)\n",
    "person3_face_encodings = encode_faces(person3_images)\n",
    "person4_face_encodings = encode_faces(person4_images)\n",
    "person5_face_encodings = encode_faces(person5_images)\n",
    "person6_face_encodings = encode_faces(person6_images)\n",
    "\n",
    "# Use average face encoding for each person\n",
    "average_person1_face_encoding = sum(person1_face_encodings) / len(person1_face_encodings)\n",
    "average_person2_face_encoding = sum(person2_face_encodings) / len(person2_face_encodings)\n",
    "average_person3_face_encoding = sum(person3_face_encodings) / len(person3_face_encodings)\n",
    "average_person4_face_encoding = sum(person4_face_encodings) / len(person4_face_encodings)\n",
    "average_person5_face_encoding = sum(person5_face_encodings) / len(person5_face_encodings)\n",
    "average_person6_face_encoding = sum(person6_face_encodings) / len(person6_face_encodings)\n",
    "\n",
    "known_face_encodings = [average_person1_face_encoding, average_person2_face_encoding,average_person3_face_encoding,average_person4_face_encoding,average_person5_face_encoding,average_person6_face_encoding]\n",
    "known_face_names = [\"Wonyoung\", \"Gaeul\",\"Rei\",\"Yujin\",\"Jiwon\",\"Leeseo\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Imbalance data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>member</th>\n",
       "      <th>total_img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wonyoung</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gaeul</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rei</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yujin</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jiwon</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Leeseo</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     member  total_img\n",
       "0  Wonyoung        223\n",
       "1     Gaeul        217\n",
       "2       Rei        208\n",
       "3     Yujin        219\n",
       "4     Jiwon        210\n",
       "5    Leeseo        206"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Your DataFrame data\n",
    "data = {'member': ['Wonyoung', 'Gaeul', 'Rei', 'Yujin', 'Jiwon', 'Leeseo'],\n",
    "        'total_img': [len(person1_images), len(person2_images), len(person3_images), len(person4_images), len(person5_images), len(person6_images)]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "normalize_rgb = lambda rgb: (rgb[0] / 255, rgb[1] / 255, rgb[2] / 255)\n",
    "colors = [normalize_rgb((160, 225, 105)), normalize_rgb((29,214,216)), normalize_rgb((255,102,102)),  normalize_rgb((249,218,66)), normalize_rgb((255,105,180)), normalize_rgb((153,50,204))]\n",
    "218,112,214\n",
    "\n",
    "plt.bar(df['member'], df['total_img'], color=colors)\n",
    "\n",
    "plt.xlabel('Member')\n",
    "plt.ylabel('Total Images')\n",
    "plt.title('Total Images by Member')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use compare_faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_faces(unknown_image, known_face_encodings, known_face_names):\n",
    "    face_locations = face_recognition.face_locations(unknown_image)\n",
    "    face_encodings = face_recognition.face_encodings(unknown_image, face_locations)\n",
    "\n",
    "    for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "        matches = face_recognition.compare_faces(known_face_encodings, face_encoding,tolerance=0.4)\n",
    "        name = \"Unknown\"\n",
    "\n",
    "        # Count the number of True matches\n",
    "        num_matches = sum(matches)\n",
    "\n",
    "        # Calculate accuracy as a percentage\n",
    "        accuracy_percent = (num_matches / len(known_face_encodings)) * 100\n",
    "\n",
    "        if True in matches:\n",
    "            match_index = matches.index(True)\n",
    "            name = known_face_names[match_index]\n",
    "            label = f\"{name} : ({accuracy_percent:.2f}%)\"\n",
    " \n",
    "          \n",
    "            if match_index == 0:\n",
    "                cv2.rectangle(frame, (left, top), (right, bottom), (105,225,160), 2)\n",
    "                cv2.rectangle(frame, (left, bottom -20), (right, bottom), (105,225,160), cv2.FILLED)\n",
    "                 # Label the face\n",
    "                cv2.putText(frame, label, (left + 6, bottom-6), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255),2)\n",
    "            elif match_index == 1:\n",
    "                cv2.rectangle(frame, (left, top), (right, bottom), (216,214,29), 2)\n",
    "                cv2.rectangle(frame, (left, bottom-20), (right, bottom), (216,214,29), cv2.FILLED)\n",
    "                # Label the face\n",
    "                cv2.putText(frame, label, (left + 6, bottom-6), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)   \n",
    "            elif match_index == 2:\n",
    "                cv2.rectangle(frame, (left, top), (right, bottom), (102,102,255), 2)\n",
    "                cv2.rectangle(frame, (left, bottom-20), (right, bottom), (102,102,255), cv2.FILLED)\n",
    "                # Label the face\n",
    "                cv2.putText(frame, label, (left + 6, bottom-6), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "            elif match_index == 3:\n",
    "                cv2.rectangle(frame, (left, top), (right, bottom), (66,218,249), 2)\n",
    "                cv2.rectangle(frame, (left, bottom-20), (right, bottom), (66,218,249), cv2.FILLED)\n",
    "                # Label the face\n",
    "                cv2.putText(frame, label, (left + 6, bottom-6), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "            elif match_index == 4:\n",
    "                cv2.rectangle(frame, (left, top), (right, bottom), (180,105,255), 2)\n",
    "                cv2.rectangle(frame, (left, bottom-20), (right, bottom), (180,105,255), cv2.FILLED)\n",
    "                # Label the face\n",
    "                cv2.putText(frame, label, (left + 6, bottom-6), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "            elif match_index == 5:\n",
    "                cv2.rectangle(frame, (left, top), (right, bottom), (204,50,153), 2)\n",
    "                cv2.rectangle(frame, (left, bottom-20), (right, bottom), (204,50,153), cv2.FILLED)\n",
    "                # Label the face\n",
    "                cv2.putText(frame, label, (left + 6, bottom-6), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)    \n",
    "       \n",
    "\n",
    "\n",
    "# Start program\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "\n",
    "# Open a video capture object\n",
    "video_path = './videos/hw2_hd.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "frame_skip = 5  # Process every 5th frame\n",
    "resize_factor = 0.7  # Resize frames to 50%\n",
    "threshold = 0.3  # Adjust this threshold as needed\n",
    "\n",
    "w = int(cap.get(3)) \n",
    "h = int(cap.get(4))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "output_video = cv2.VideoWriter('mv2_compare_faces.avi', fourcc, fps, (w,h))\n",
    "\n",
    "while cap.isOpened():\n",
    "    # Read a single frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Break the loop if the video has ended\n",
    "    if not ret:\n",
    "        break\n",
    "   \n",
    "    # Convert the frame from BGR to RGB (OpenCV uses BGR by default)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Create a Pillow ImageDraw object to draw on the image\n",
    "    pil_image = Image.fromarray(rgb_frame)\n",
    "    draw = ImageDraw.Draw(pil_image)\n",
    "\n",
    "\n",
    "    # Recognize faces in the current frame\n",
    "    frame_with_recognition = recognize_faces(rgb_frame, known_face_encodings, known_face_names)\n",
    "\n",
    "    output_video.write(frame)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Face Recognition Result', frame)\n",
    "\n",
    "    # Break the loop if 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "# Release the video capture object and close all windows\n",
    "cap.release()\n",
    "output_video.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use face_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_faces(known_face_encodings, face_encoding, threshold=0.4):\n",
    "    # Calculate cosine similarity between the known face encodings and the current face encoding\n",
    "    similarities = face_recognition.face_distance(known_face_encodings, face_encoding)\n",
    "    # Compare each similarity with the threshold to determine matches\n",
    "    matches = list(similarity <= threshold for similarity in similarities)\n",
    "\n",
    "    return matches, similarities\n",
    "\n",
    "\n",
    "\n",
    "def recognize_faces(unknown_image, known_face_encodings, known_face_names):\n",
    "    face_locations = face_recognition.face_locations(unknown_image)\n",
    "    face_encodings = face_recognition.face_encodings(unknown_image, face_locations)\n",
    "\n",
    "    for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings):\n",
    "        matches, similarities = compare_faces(known_face_encodings, face_encoding, threshold=0.4)\n",
    "        name = \"Unknown\"\n",
    "\n",
    "        # Find the index of the best match (lowest distance)\n",
    "        best_match_index = np.argmin(similarities)\n",
    "\n",
    "        # Get the accuracy percentage for the best match\n",
    "        accuracy_percent = (1 - similarities[best_match_index]) * 100\n",
    "\n",
    "        if matches[best_match_index]:\n",
    "            match_index = matches.index(True)\n",
    "            name = known_face_names[match_index]\n",
    "            label = f\"{name} : ({accuracy_percent:.2f}%)\"\n",
    "\n",
    "            if match_index == 0:\n",
    "                cv2.rectangle(frame, (left, top), (right, bottom), (105,225,160), 2)\n",
    "                cv2.rectangle(frame, (left, bottom -20), (right, bottom), (105,225,160), cv2.FILLED)\n",
    "                 # Label the face\n",
    "                cv2.putText(frame, label, (left + 6, bottom-6), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255),2)\n",
    "            elif match_index == 1:\n",
    "                cv2.rectangle(frame, (left, top), (right, bottom), (216,214,29), 2)\n",
    "                cv2.rectangle(frame, (left, bottom-20), (right, bottom), (216,214,29), cv2.FILLED)\n",
    "                # Label the face\n",
    "                cv2.putText(frame, label, (left + 6, bottom-6), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)   \n",
    "            elif match_index == 2:\n",
    "                cv2.rectangle(frame, (left, top), (right, bottom), (102,102,255), 2)\n",
    "                cv2.rectangle(frame, (left, bottom-20), (right, bottom), (102,102,255), cv2.FILLED)\n",
    "                # Label the face\n",
    "                cv2.putText(frame, label, (left + 6, bottom-6), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "            elif match_index == 3:\n",
    "                cv2.rectangle(frame, (left, top), (right, bottom), (66,218,249), 2)\n",
    "                cv2.rectangle(frame, (left, bottom-20), (right, bottom), (66,218,249), cv2.FILLED)\n",
    "                # Label the face\n",
    "                cv2.putText(frame, label, (left + 6, bottom-6), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "            elif match_index == 4:\n",
    "                cv2.rectangle(frame, (left, top), (right, bottom), (180,105,255), 2)\n",
    "                cv2.rectangle(frame, (left, bottom-20), (right, bottom), (180,105,255), cv2.FILLED)\n",
    "                # Label the face\n",
    "                cv2.putText(frame, label, (left + 6, bottom-6), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)\n",
    "            elif match_index == 5:\n",
    "                cv2.rectangle(frame, (left, top), (right, bottom), (204,50,153), 2)\n",
    "                cv2.rectangle(frame, (left, bottom-20), (right, bottom), (204,50,153), cv2.FILLED)\n",
    "                # Label the face\n",
    "                cv2.putText(frame, label, (left + 6, bottom-6), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255,255,255), 2)    \n",
    "       \n",
    "\n",
    "\n",
    "# Start program\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "\n",
    "# Open a video capture object\n",
    "video_path = './videos/hw2_hd.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video.\")\n",
    "    exit()\n",
    "\n",
    "frame_skip = 5  # Process every 5th frame\n",
    "resize_factor = 0.7  # Resize frames to 50%\n",
    "threshold = 0.3  # Adjust this threshold as needed\n",
    "\n",
    "w = int(cap.get(3)) \n",
    "h = int(cap.get(4))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "output_video = cv2.VideoWriter('mv2_distance.avi', fourcc, fps, (w,h))\n",
    "\n",
    "while cap.isOpened():\n",
    "    # Read a single frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # Break the loop if the video has ended\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "       \n",
    "    # Convert the frame from BGR to RGB (OpenCV uses BGR by default)\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Create a Pillow ImageDraw object to draw on the image\n",
    "    pil_image = Image.fromarray(rgb_frame)\n",
    "    draw = ImageDraw.Draw(pil_image)\n",
    "\n",
    "    # Recognize faces in the current frame\n",
    "    frame_with_recognition = recognize_faces(rgb_frame, known_face_encodings, known_face_names)\n",
    "\n",
    "    output_video.write(frame)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Face Recognition Result', frame)\n",
    "\n",
    "    # Break the loop if 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "\n",
    "# Release the video capture object and close all windows\n",
    "cap.release()\n",
    "output_video.release()\n",
    "# output_video = cv2.VideoWriter('output2_mv2.avi', fourcc, 30, (w, h))\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ใส่เพลง"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from moviepy.editor import VideoFileClip\n",
    "from moviepy.audio.io.AudioFileClip import AudioFileClip\n",
    "\n",
    "# Replace 'input_video.mp4' and 'input_audio.wav' with the paths to your video and audio files\n",
    "input_video_path = 'mv2_distance.avi'\n",
    "input_audio_path = './videos/hw2_hd.mp4'\n",
    "\n",
    "# Replace 'output_video_with_audio.mp4' with the desired name for your output video file\n",
    "output_video_path = 'mv2_with_audio_v3_distance.mp4'\n",
    "\n",
    "# Load video clip\n",
    "video_clip = VideoFileClip(input_video_path)\n",
    "\n",
    "# Load audio clip\n",
    "audio_clip = AudioFileClip(input_audio_path)\n",
    "\n",
    "# Set video duration to match audio duration\n",
    "video_clip = video_clip.set_duration(audio_clip.duration)\n",
    "\n",
    "# Set audio of the video clip\n",
    "video_clip = video_clip.set_audio(audio_clip)\n",
    "\n",
    "# Write the new video file\n",
    "video_clip.write_videofile(output_video_path, codec='libx264', audio_codec='aac')\n",
    "\n",
    "# Close the clips\n",
    "video_clip.close()\n",
    "audio_clip.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
